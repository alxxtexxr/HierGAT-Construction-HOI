{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment: `py39_torch271`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from dacite import from_dict\n",
    "\n",
    "from pyrutils.torch.train_utils import train, save_checkpoint\n",
    "from pyrutils.torch.multi_task import MultiTaskLossLearner\n",
    "from vhoi.data_loading import (\n",
    "    input_size_from_data_loader, \n",
    "    select_model_data_feeder, \n",
    "    select_model_data_fetcher,\n",
    ")\n",
    "from vhoi.data_loading_custom import (\n",
    "    create_data,\n",
    "    create_data_loader\n",
    ")\n",
    "from vhoi.losses import (\n",
    "    select_loss, \n",
    "    decide_num_main_losses, \n",
    "    select_loss_types, \n",
    "    select_loss_learning_mask,\n",
    ")\n",
    "from vhoi.models import load_model_weights\n",
    "from vhoi.models_custom import TGGCN\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)   # Python的随机性\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)    # 设置Python哈希种子，为了禁止hash随机化，使得实验可复现\n",
    "np.random.seed(seed)   # numpy的随机性\n",
    "torch.manual_seed(seed)   # torch的CPU随机性，为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed)   # torch的GPU随机性，为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.   torch的GPU随机性，为所有GPU设置随机种子\n",
    "torch.backends.cudnn.benchmark = False   # if benchmark=True, deterministic will be False\n",
    "torch.backends.cudnn.deterministic = True   # 选择确定性算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictMixin:\n",
    "    def get(self, key, default_value=None):\n",
    "        return getattr(self, key, default_value)\n",
    "\n",
    "    def as_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "@dataclass\n",
    "class Resources(DictMixin):\n",
    "    use_gpu: bool\n",
    "    num_threads: int\n",
    "\n",
    "@dataclass\n",
    "class ModelMetadata(DictMixin):\n",
    "    model_name: str\n",
    "    input_type: str\n",
    "\n",
    "@dataclass\n",
    "class ModelParameters(DictMixin):\n",
    "    add_segment_length: int\n",
    "    add_time_position: int\n",
    "    time_position_strategy: str\n",
    "    positional_encoding_style: str\n",
    "    attention_style: str\n",
    "    bias: bool\n",
    "    cat_level_states: int\n",
    "    discrete_networks_num_layers: int\n",
    "    discrete_optimization_strategy: str\n",
    "    filter_discrete_updates: bool\n",
    "    gcn_node: int\n",
    "    hidden_size: int\n",
    "    message_humans_to_human: bool\n",
    "    message_human_to_objects: bool\n",
    "    message_objects_to_human: bool\n",
    "    message_objects_to_object: bool\n",
    "    message_geometry_to_objects: bool\n",
    "    message_geometry_to_human: bool\n",
    "    message_segment: bool\n",
    "    message_type: str\n",
    "    message_granularity: str\n",
    "    message_aggregation: str\n",
    "    object_segment_update_strategy: str\n",
    "    share_level_mlps: int\n",
    "    update_segment_threshold: float\n",
    "\n",
    "@dataclass\n",
    "class ModelOptimization(DictMixin):\n",
    "    batch_size: int\n",
    "    clip_gradient_at: float\n",
    "    epochs: int\n",
    "    learning_rate: float\n",
    "    val_fraction: float\n",
    "\n",
    "@dataclass\n",
    "class BudgetLoss(DictMixin):\n",
    "    add: bool\n",
    "    human_weight: float\n",
    "    object_weight: float\n",
    "\n",
    "@dataclass\n",
    "class SegmentationLoss(DictMixin):\n",
    "    add: bool\n",
    "    pretrain: bool\n",
    "    sigma: float\n",
    "    weight: float\n",
    "\n",
    "@dataclass\n",
    "class ModelMisc(DictMixin):\n",
    "    anticipation_loss_weight: float\n",
    "    budget_loss: BudgetLoss\n",
    "    first_level_loss_weight: float\n",
    "    impose_segmentation_pattern: int\n",
    "    input_human_segmentation: bool\n",
    "    input_object_segmentation: bool\n",
    "    make_attention_distance_based: bool\n",
    "    multi_task_loss_learner: bool\n",
    "    pretrained: bool\n",
    "    pretrained_path: Optional[str]\n",
    "    segmentation_loss: SegmentationLoss\n",
    "\n",
    "@dataclass\n",
    "class ModelLogging(DictMixin):\n",
    "    root_log_dir: str\n",
    "    checkpoint_name: str\n",
    "    log_dir: str\n",
    "\n",
    "@dataclass\n",
    "class Models(DictMixin):\n",
    "    metadata: ModelMetadata\n",
    "    parameters: ModelParameters\n",
    "    optimization: ModelOptimization\n",
    "    misc: ModelMisc\n",
    "    logging: ModelLogging\n",
    "\n",
    "@dataclass\n",
    "class Data(DictMixin):\n",
    "    name: str\n",
    "    path: str\n",
    "    path_zarr: str\n",
    "    path_obb_zarr: str\n",
    "    path_hbb_zarr: str\n",
    "    path_hps_zarr: str\n",
    "    cross_validation_test_subject: str\n",
    "    scaling_strategy: Optional[str]\n",
    "    downsampling: int\n",
    "\n",
    "@dataclass\n",
    "class Config(DictMixin):\n",
    "    resources: Resources\n",
    "    models: Models\n",
    "    data: Data\n",
    "    \n",
    "metadata_dict = {\n",
    "    \"model_name\": \"2G-GCN\",\n",
    "    \"input_type\": \"multiple\"\n",
    "}\n",
    "\n",
    "parameters_dict = {\n",
    "    \"add_segment_length\": 0,  # length of the segment to the segment-level rnn. 0 is off and 1 is on.\n",
    "    \"add_time_position\": 0,  # absolute time position to the segment-level rnn. 0 is off and 1 is on.\n",
    "    \"time_position_strategy\": \"s\",  # input time position to segment [s] or discrete update [u].\n",
    "    \"positional_encoding_style\": \"e\",  # e [embedding] or p [periodic].\n",
    "    \"attention_style\": \"v3\",  # v1 [concat], v2 [dot-product], v3 [scaled_dot-product], v4 [general]\n",
    "    \"bias\": True,\n",
    "    \"cat_level_states\": 0,  # concatenate first and second level hidden states for predictors MLPs.\n",
    "    \"discrete_networks_num_layers\": 1,  # depth of the state change detector MLP.\n",
    "    \"discrete_optimization_strategy\": \"gs\",  # straight-through [st] or gumbel-sigmoid [gs]\n",
    "    \"filter_discrete_updates\": False,  # maxima filter for soft output of state change detector.\n",
    "    \"gcn_node\": 25,  # custom, original: 19 for cad120, 30 for bimanual, 26 for mphoi\n",
    "    \"hidden_size\": 512,  # 512 for cad120 & mphoi; 64 for bimanual\n",
    "    \"message_humans_to_human\": False, # custom, original: True\n",
    "    \"message_human_to_objects\": True,\n",
    "    \"message_objects_to_human\": True,\n",
    "    \"message_objects_to_object\": False, # custom, original: True\n",
    "    \"message_geometry_to_objects\": True,\n",
    "    \"message_geometry_to_human\": True,  # custom, original: False\n",
    "    \"message_segment\": True,\n",
    "    \"message_type\": \"v2\",  # v1 [relational] or v2 [non-relational]\n",
    "    \"message_granularity\": \"v1\",  # v1 [generic] or v2 [specific]\n",
    "    \"message_aggregation\": \"att\",  # mean_pooling [mp] or attention [att]\n",
    "    \"object_segment_update_strategy\": \"ind\",  # same_as_human [sah], independent [ind], or conditional_on_human [coh]\n",
    "    \"share_level_mlps\": 0,  # whether to share [1] or not [0] the prediction MLPs of the levels.\n",
    "    \"update_segment_threshold\": 0.5  # [0.0, 1.0)\n",
    "}\n",
    "\n",
    "optimization_dict = {\n",
    "    \"batch_size\": 8,  # mphoi:8; cad120:16; bimanual: 32\n",
    "    \"clip_gradient_at\": 0.0,\n",
    "    \"epochs\": 40, # custom, original: cad120 & mphoi:40; bimanual: 60\n",
    "    \"learning_rate\": 1e-4,  # mphoi:1e-4; cad120 & bimanual:1e-3\n",
    "    \"val_fraction\": 0.1\n",
    "}\n",
    "\n",
    "data_dict = {\n",
    "    \"name\": \"mphoi\",\n",
    "    \"path\": f\"{os.getcwd()}/data/MPHOI/MPHOI/mphoi_ground_truth_labels.json\",\n",
    "    \"path_zarr\": f\"{os.getcwd()}/data/MPHOI/MPHOI/mphoi_derived_features/faster_rcnn.zarr\",\n",
    "    \"path_obb_zarr\": f\"{os.getcwd()}/data/MPHOI/MPHOI/mphoi_derived_features/object_bounding_boxes.zarr\",\n",
    "    \"path_hbb_zarr\": f\"{os.getcwd()}/data/MPHOI/MPHOI/mphoi_derived_features/human_bounding_boxes.zarr\",\n",
    "    \"path_hps_zarr\": f\"{os.getcwd()}/data/MPHOI/MPHOI/mphoi_derived_features/human_pose.zarr\",\n",
    "    \"cross_validation_test_subject\": \"Subject14\",  # Subject45, Subject25, Subject14\n",
    "    \"scaling_strategy\": None,  # null or \"standard\"\n",
    "    \"downsampling\": 1 # custom, original: 3, 1 = full FPS, 2 = half FPS, ...\n",
    "}\n",
    "\n",
    "# root_log_dir = f\"{os.getcwd()}/outputs_hiergat/{data_dict['name']}/{metadata_dict['model_name']}\"\n",
    "root_log_dir = f\"{os.getcwd()}/outputs_hiergat/custom\"\n",
    "checkpoint_name = (\n",
    "    f\"hs{parameters_dict['hidden_size']}_e{optimization_dict['epochs']}_bs{optimization_dict['batch_size']}_\"\n",
    "    f\"lr{optimization_dict['learning_rate']}_{parameters_dict['update_segment_threshold']}_{data_dict['cross_validation_test_subject']}\"\n",
    ")\n",
    "log_dir = f\"{root_log_dir}/{checkpoint_name}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "cfg_dict = {\n",
    "    \"resources\": {\n",
    "        \"use_gpu\": True,\n",
    "        \"num_threads\": 32\n",
    "    },\n",
    "    \"models\": {\n",
    "        \"metadata\": metadata_dict,\n",
    "        \"parameters\": parameters_dict,\n",
    "        \"optimization\": optimization_dict,\n",
    "        \"misc\": {\n",
    "            \"anticipation_loss_weight\": 1.0,\n",
    "            \"budget_loss\": {\n",
    "                \"add\": False,\n",
    "                \"human_weight\": 1.0,\n",
    "                \"object_weight\": 1.0\n",
    "            },\n",
    "            \"first_level_loss_weight\": 0.0,  # if positive, first level does frame-level prediction\n",
    "            \"impose_segmentation_pattern\": 1,  # 0 [no pattern], 1 [all ones]\n",
    "            \"input_human_segmentation\": False,  # (was \"flase\" in YAML, corrected here)\n",
    "            \"input_object_segmentation\": False,\n",
    "            \"make_attention_distance_based\": True,  # only meaningful if message_aggregation is attention\n",
    "            \"multi_task_loss_learner\": False,\n",
    "            \"pretrained\": False,  # unfortunately need two entries for checkpoint name\n",
    "            \"pretrained_path\": None,  # specified parameters must match pre-trained model\n",
    "            \"segmentation_loss\": {\n",
    "                \"add\": False,\n",
    "                \"pretrain\": False,\n",
    "                \"sigma\": 0.0,  # Gaussian smoothing\n",
    "                \"weight\": 1.0\n",
    "            }\n",
    "        },\n",
    "        \"logging\": {\n",
    "            \"root_log_dir\": root_log_dir,\n",
    "            \"checkpoint_name\": checkpoint_name,\n",
    "            \"log_dir\": log_dir\n",
    "        },\n",
    "    },\n",
    "    \"data\": data_dict,\n",
    "}\n",
    "\n",
    "cfg = from_dict(data_class=Config, data=cfg_dict)\n",
    "\n",
    "torch.set_num_threads(cfg.resources.num_threads)\n",
    "model_name, model_input_type = cfg.models.metadata.model_name, cfg.models.metadata.input_type\n",
    "batch_size, val_fraction = cfg.models.optimization.batch_size, cfg.models.optimization.val_fraction\n",
    "misc_dict = cfg.get('misc', default_value={})\n",
    "sigma = misc_dict.get('segmentation_loss', {}).get('sigma', 0.0)\n",
    "scaling_strategy = cfg.data.scaling_strategy\n",
    "downsampling = cfg.data.downsampling\n",
    "\n",
    "num_classes = 18\n",
    "# features_dir = Path('/root/vs-gats-plaster/deepsort/outputs/anno_test_8/features')\n",
    "features_dirs = [\n",
    "    Path('/root/vs-gats-plaster/deepsort/outputs/C0485 (preparing)_full_temporal_1s/features'),\n",
    "    Path('/root/vs-gats-plaster/deepsort/outputs/C0496_r_full_temporal_1s/features'),\n",
    "    Path('/root/vs-gats-plaster/deepsort/outputs/C0529_c_full_temporal_1s/features'),\n",
    "    Path('/root/vs-gats-plaster/deepsort/outputs/C0505_r_full_temporal_1s/features'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action label value counts:\n",
      "action_label\n",
      "16    1333\n",
      "17     281\n",
      "12     246\n",
      "5      227\n",
      "0      224\n",
      "4      152\n",
      "7       61\n",
      "2       58\n",
      "9       47\n",
      "1       41\n",
      "15      28\n",
      "11      10\n",
      "3        5\n",
      "14       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Action label value counts (balanced):\n",
      "action_label\n",
      "17    281\n",
      "16    281\n",
      "12    246\n",
      "5     227\n",
      "0     224\n",
      "4     152\n",
      "7      61\n",
      "2      58\n",
      "9      47\n",
      "1      41\n",
      "15     28\n",
      "11     10\n",
      "3       5\n",
      "14      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "\n",
    "feature_dirs_dict = []\n",
    "for features_dir in features_dirs:\n",
    "    for dir in features_dir.iterdir():\n",
    "        action_label = int(str(dir).rsplit('_action_')[-1])\n",
    "        feature_dirs_dict.append({\n",
    "            'dir': dir,\n",
    "            'action_label': action_label,\n",
    "        })\n",
    "feature_dirs_df = pd.DataFrame(feature_dirs_dict)\n",
    "\n",
    "print(\"Action label value counts:\")\n",
    "print(feature_dirs_df['action_label'].value_counts())\n",
    "print()\n",
    "\n",
    "# Downsample majority `action_label` (16)\n",
    "feature_dirs_df_majority = feature_dirs_df[feature_dirs_df['action_label'] == 16]\n",
    "feature_dirs_df_others   = feature_dirs_df[feature_dirs_df['action_label'] != 16]\n",
    "\n",
    "feature_dirs_df_majority_downsampled = feature_dirs_df_majority.sample(n=281, random_state=seed)\n",
    "\n",
    "feature_dirs_df_balanced = pd.concat([feature_dirs_df_majority_downsampled, feature_dirs_df_others])\n",
    "feature_dirs_df_balanced = feature_dirs_df_balanced.sample(frac=1, random_state=seed).reset_index(drop=True) # Shuffle \n",
    "\n",
    "print(\"Action label value counts (balanced):\")\n",
    "print(feature_dirs_df_balanced['action_label'].value_counts())\n",
    "\n",
    "\n",
    "# def split_list(lst, ratio=0.2):\n",
    "#     n = len(lst)\n",
    "#     split_idx = int(n * ratio) # number of items in first list\n",
    "#     list1 = lst[split_idx:]\n",
    "#     list2 = lst[:split_idx]\n",
    "#     return list1, list2\n",
    "# train_feature_dirs, val_test_feature_dirs = split_list(feature_dirs, ratio=val_fraction*2)\n",
    "# mid = len(val_test_feature_dirs) // 2\n",
    "# val_feature_dirs = val_test_feature_dirs[:mid]\n",
    "# test_feature_dirs = val_test_feature_dirs[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_test_df = train_test_split(\n",
    "    feature_dirs_df_balanced,\n",
    "    test_size=val_fraction*2,\n",
    "    stratify=feature_dirs_df_balanced[\"action_label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Now split train_val into train and val\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df,\n",
    "    test_size=0.5,\n",
    "    stratify=val_test_df[\"action_label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Extract just the paths\n",
    "train_paths = train_df[\"path\"].tolist()\n",
    "val_paths   = val_df[\"path\"].tolist()\n",
    "test_paths  = test_df[\"path\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_data(train_feature_dirs)\n",
    "val_data = create_data(val_feature_dirs)\n",
    "test_data = create_data(test_feature_dirs)\n",
    "\n",
    "train_loader, scalers, _ = create_data_loader(\n",
    "    *train_data, \n",
    "    model_name, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    scaling_strategy=scaling_strategy, \n",
    "    sigma=sigma,\n",
    "    downsampling=downsampling,\n",
    ")\n",
    "val_loader, _, _ = create_data_loader(\n",
    "    *val_data, \n",
    "    model_name, \n",
    "    batch_size=len(val_data[0]),\n",
    "    shuffle=False, \n",
    "    scalers=scalers, \n",
    "    sigma=sigma, \n",
    "    downsampling=downsampling,\n",
    ")\n",
    "test_loader, _, _ = create_data_loader(\n",
    "    *test_data, \n",
    "    model_name, \n",
    "    batch_size=len(test_data[0]),\n",
    "    shuffle=False, \n",
    "    scalers=scalers, \n",
    "    sigma=sigma, \n",
    "    downsampling=downsampling,\n",
    ")\n",
    "input_size = input_size_from_data_loader(train_loader, model_name, model_input_type)\n",
    "data_info = {'input_size': input_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [   1/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   5.7421  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  2.8639  NLL_SAP:  2.8781\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   3.3417  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.6561  NLL_SAP:  1.6856\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   2.8463  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.4183  NLL_SAP:  1.4280\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   2.8758  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.4106  NLL_SAP:  1.4652\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   3.0809  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.5313  NLL_SAP:  1.5496\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   1.5694  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8012  NLL_SAP:  0.7682\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   1.4068  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7167  NLL_SAP:  0.6902\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   1.4860  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7481  NLL_SAP:  0.7379\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   2.1515  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.0742  NLL_SAP:  1.0773\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   1.9099  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.9450  NLL_SAP:  0.9649\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   1.8669  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.9296  NLL_SAP:  0.9372\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   0.8843  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4301  NLL_SAP:  0.4542\n",
      "     (Train) Loss:  1.2846   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.6433   NLL_SAP:  0.6413\n",
      "(Validation) Loss:  11.2363   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  5.6499   NLL_SAP:  5.5864\n",
      "\n",
      "Epoch: [   2/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   0.7505  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3779  NLL_SAP:  0.3726\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   0.3616  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1795  NLL_SAP:  0.1821\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   1.6435  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8244  NLL_SAP:  0.8191\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   1.6251  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8039  NLL_SAP:  0.8212\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   1.6962  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8462  NLL_SAP:  0.8501\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   1.9317  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.9666  NLL_SAP:  0.9651\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   0.5651  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2870  NLL_SAP:  0.2781\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   1.5458  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7783  NLL_SAP:  0.7675\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   2.9706  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.4485  NLL_SAP:  1.5221\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.5430  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2739  NLL_SAP:  0.2690\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   2.5288  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.2477  NLL_SAP:  1.2811\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   2.6765  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.3432  NLL_SAP:  1.3333\n",
      "     (Train) Loss:  0.8569   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.4309   NLL_SAP:  0.4260\n",
      "(Validation) Loss:  12.0784   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  6.0752   NLL_SAP:  6.0033\n",
      "\n",
      "Epoch: [   3/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   1.0030  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5034  NLL_SAP:  0.4996\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   0.5759  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2874  NLL_SAP:  0.2885\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   1.1654  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5848  NLL_SAP:  0.5806\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.4573  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2305  NLL_SAP:  0.2268\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   0.7510  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3777  NLL_SAP:  0.3733\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   0.9619  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4879  NLL_SAP:  0.4740\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   0.6311  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3192  NLL_SAP:  0.3119\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   1.0462  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5219  NLL_SAP:  0.5243\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   2.1889  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.0961  NLL_SAP:  1.0929\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.8487  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4285  NLL_SAP:  0.4202\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   1.1284  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5589  NLL_SAP:  0.5695\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   1.1512  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5737  NLL_SAP:  0.5775\n",
      "     (Train) Loss:  0.7467   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.3743   NLL_SAP:  0.3724\n",
      "(Validation) Loss:  12.2434   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  6.1329   NLL_SAP:  6.1105\n",
      "\n",
      "Epoch: [   4/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   0.5982  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2990  NLL_SAP:  0.2992\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   0.4244  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2128  NLL_SAP:  0.2117\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   0.9278  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4763  NLL_SAP:  0.4515\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.4560  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2328  NLL_SAP:  0.2232\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   0.3588  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1790  NLL_SAP:  0.1798\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   1.8238  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8946  NLL_SAP:  0.9291\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   1.0090  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5190  NLL_SAP:  0.4901\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   0.7844  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3912  NLL_SAP:  0.3932\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   0.8341  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4224  NLL_SAP:  0.4117\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.1865  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.0944  NLL_SAP:  0.0921\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   1.2622  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.6278  NLL_SAP:  0.6344\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   0.1770  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.0885  NLL_SAP:  0.0885\n",
      "     (Train) Loss:  0.7424   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.3720   NLL_SAP:  0.3704\n",
      "(Validation) Loss:  13.7016   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  6.8412   NLL_SAP:  6.8604\n",
      "\n",
      "Epoch: [   5/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   0.3159  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1626  NLL_SAP:  0.1533\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   0.5020  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2512  NLL_SAP:  0.2509\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   0.2691  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1381  NLL_SAP:  0.1310\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.8180  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4121  NLL_SAP:  0.4059\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   0.3316  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1675  NLL_SAP:  0.1642\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   1.9538  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.9833  NLL_SAP:  0.9705\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   0.9601  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4767  NLL_SAP:  0.4834\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   1.7301  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.8771  NLL_SAP:  0.8531\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   1.1936  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5988  NLL_SAP:  0.5948\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.5477  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2755  NLL_SAP:  0.2723\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   0.3824  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1889  NLL_SAP:  0.1935\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   1.1233  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.5500  NLL_SAP:  0.5733\n",
      "     (Train) Loss:  0.6896   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.3453   NLL_SAP:  0.3443\n",
      "(Validation) Loss:  13.3828   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  6.6786   NLL_SAP:  6.7042\n",
      "\n",
      "Epoch: [   6/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   1.4417  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7346  NLL_SAP:  0.7072\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   1.2615  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.6344  NLL_SAP:  0.6271\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   1.3545  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.6833  NLL_SAP:  0.6712\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.5420  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2749  NLL_SAP:  0.2671\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   0.6770  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3447  NLL_SAP:  0.3323\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   0.6245  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3148  NLL_SAP:  0.3096\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   0.3392  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1639  NLL_SAP:  0.1753\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   0.2019  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1024  NLL_SAP:  0.0994\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   0.7985  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.3977  NLL_SAP:  0.4007\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.5936  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2975  NLL_SAP:  0.2961\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   0.9214  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4568  NLL_SAP:  0.4646\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   2.5411  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.2731  NLL_SAP:  1.2680\n",
      "     (Train) Loss:  0.6711   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.3356   NLL_SAP:  0.3356\n",
      "(Validation) Loss:  13.9867   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  6.9799   NLL_SAP:  7.0068\n",
      "\n",
      "Epoch: [   7/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   0.2845  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1417  NLL_SAP:  0.1428\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   0.4554  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2247  NLL_SAP:  0.2308\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   0.1629  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.0826  NLL_SAP:  0.0803\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.5006  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2559  NLL_SAP:  0.2446\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   1.8240  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.9051  NLL_SAP:  0.9189\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   0.8638  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4401  NLL_SAP:  0.4236\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   2.1524  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.0665  NLL_SAP:  1.0858\n",
      "(Train) Batch [  1408/  2174 ( 65%)]  Loss:   2.7327  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.3748  NLL_SAP:  1.3579\n",
      "(Train) Batch [  1608/  2174 ( 74%)]  Loss:   1.4287  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7102  NLL_SAP:  0.7185\n",
      "(Train) Batch [  1808/  2174 ( 83%)]  Loss:   0.3624  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1773  NLL_SAP:  0.1851\n",
      "(Train) Batch [  2008/  2174 ( 92%)]  Loss:   0.3076  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1517  NLL_SAP:  0.1559\n",
      "(Train) Batch [  2174/  2174 (100%)]  Loss:   0.9875  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4891  NLL_SAP:  0.4985\n",
      "     (Train) Loss:  0.8901   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  0.4391   NLL_SAP:  0.4510\n",
      "(Validation) Loss:  15.9157   B_HS:  0.0000   BCE_HS:  0.0000   NLL_SAR_F:  0.0000   NLL_SAP_F:  0.0000   NLL_SAR:  8.0253   NLL_SAP:  7.8905\n",
      "\n",
      "Epoch: [   8/  40]\n",
      "(Train) Batch [     8/  2174 (  0%)]  Loss:   0.4459  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2053  NLL_SAP:  0.2406\n",
      "(Train) Batch [   208/  2174 ( 10%)]  Loss:   1.5349  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.7820  NLL_SAP:  0.7529\n",
      "(Train) Batch [   408/  2174 ( 19%)]  Loss:   0.5004  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.2546  NLL_SAP:  0.2458\n",
      "(Train) Batch [   608/  2174 ( 28%)]  Loss:   0.2339  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.1148  NLL_SAP:  0.1191\n",
      "(Train) Batch [   808/  2174 ( 37%)]  Loss:   2.5399  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  1.2968  NLL_SAP:  1.2431\n",
      "(Train) Batch [  1008/  2174 ( 46%)]  Loss:   0.8914  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.4465  NLL_SAP:  0.4449\n",
      "(Train) Batch [  1208/  2174 ( 56%)]  Loss:   1.2484  B_HS:  0.0000  BCE_HS:  0.0000  NLL_SAR_F:  0.0000  NLL_SAP_F:  0.0000  NLL_SAR:  0.6271  NLL_SAP:  0.6213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/HierGAT-2025/vhoi/models_custom.py:638\u001b[0m, in \u001b[0;36mTGGCN.forward\u001b[0;34m(self, x_human, x_objects, objects_mask, human_segmentation, objects_segmentation, human_human_distances, human_object_distances, object_object_distances, steps_per_example, inspect_model)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     u_hsth \u001b[38;5;241m=\u001b[39m u_hsths \u001b[38;5;241m=\u001b[39m \u001b[43mhuman_segmentation\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m feed_model_data \u001b[38;5;241m=\u001b[39m select_model_data_feeder(model_name, model_input_type, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmisc_dict)\n\u001b[1;32m     26\u001b[0m num_main_losses \u001b[38;5;241m=\u001b[39m decide_num_main_losses(model_name, dataset_name, {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmisc_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m})\n\u001b[0;32m---> 27\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_gradient_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_gradient_at\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_model_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_model_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_model_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_model_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmtll_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmtll_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_main_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_main_losses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensorboard_log_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mlog_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/pyrutils/torch/train_utils.py:53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epochs, device, loss_names, clip_gradient_at, fetch_model_data, feed_model_data, val_loader, initial_epoch, mtll_model, print_raw_losses, num_main_losses, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(initial_epoch, epochs \u001b[38;5;241m+\u001b[39m initial_epoch):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39minitial_epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_gradient_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_gradient_at\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mfetch_model_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_model_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_model_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_model_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmtll_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmtll_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_main_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_main_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     current_train_loss, current_train_losses, current_train_raw_loss, current_train_raw_losses \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     58\u001b[0m         test(model, data_loader\u001b[38;5;241m=\u001b[39mtrain_loader, criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     59\u001b[0m              device\u001b[38;5;241m=\u001b[39mdevice, loss_names\u001b[38;5;241m=\u001b[39mloss_names, fetch_model_data\u001b[38;5;241m=\u001b[39mfetch_model_data,\n\u001b[1;32m     60\u001b[0m              feed_model_data\u001b[38;5;241m=\u001b[39mfeed_model_data, test_set_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, mtll_model\u001b[38;5;241m=\u001b[39mmtll_model,\n\u001b[1;32m     61\u001b[0m              print_raw_losses\u001b[38;5;241m=\u001b[39mprint_raw_losses, num_main_losses\u001b[38;5;241m=\u001b[39mnum_main_losses, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     62\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend([current_train_loss, current_train_losses])\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/pyrutils/torch/train_utils.py:146\u001b[0m, in \u001b[0;36mtrain_single_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, device, loss_names, clip_gradient_at, fetch_model_data, feed_model_data, log_interval, mtll_model, num_main_losses, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m data, target \u001b[38;5;241m=\u001b[39m fetch_model_data(dataset, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    145\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 146\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfeed_model_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m losses \u001b[38;5;241m=\u001b[39m criterion(output, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mtll_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/vhoi/data_loading.py:1281\u001b[0m, in \u001b[0;36mgcn_forward\u001b[0;34m(model, data, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m model_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps_per_example\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m   1280\u001b[0m model_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minspect_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minspect_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39_torch271/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39_torch271/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/vhoi/models_custom.py:640\u001b[0m, in \u001b[0;36mTGGCN.forward\u001b[0;34m(self, x_human, x_objects, objects_mask, human_segmentation, objects_segmentation, human_human_distances, human_object_distances, object_object_distances, steps_per_example, inspect_model)\u001b[0m\n\u001b[1;32m    638\u001b[0m     u_hsth \u001b[38;5;241m=\u001b[39m u_hsths \u001b[38;5;241m=\u001b[39m human_segmentation[:, t:t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, h]\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 640\u001b[0m     u_hsth, u_hsths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_human_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_hfth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_hfth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_hfth_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_hfth_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_hhth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_ohth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_shth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_tt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m (num_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    642\u001b[0m         u_hsth[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/vhoi/models_custom.py:1457\u001b[0m, in \u001b[0;36mTGGCN._update_human_segment\u001b[0;34m(self, x_hfth, h_hfth, x_hfth_t, h_hfth_t, m_hhth, m_ohth, m_shth, x_tt)\u001b[0m\n\u001b[1;32m   1455\u001b[0m update_human_segment_input \u001b[38;5;241m=\u001b[39m cat_valid_tensors([update_human_segment_input, update_human_segment_input_t], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1456\u001b[0m u_hsts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_update_human_segment_mlp(update_human_segment_input)\n\u001b[0;32m-> 1457\u001b[0m u_hst, u_hsts \u001b[38;5;241m=\u001b[39m \u001b[43mdiscrete_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_hsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscrete_optimization_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_segment_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m u_hst, u_hsts\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/vhoi/models.py:1720\u001b[0m, in \u001b[0;36mdiscrete_estimator\u001b[0;34m(x, strategy, threshold)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m straight_through_estimator(x, threshold), x\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgumbel-sigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[0;32m-> 1720\u001b[0m     z, x \u001b[38;5;241m=\u001b[39m \u001b[43mstraight_through_gumbel_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z, x\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/pyrutils/torch/distributions.py:33\u001b[0m, in \u001b[0;36mstraight_through_gumbel_sigmoid\u001b[0;34m(probabilities, temperature, threshold)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstraight_through_gumbel_sigmoid\u001b[39m(probabilities: torch\u001b[38;5;241m.\u001b[39mTensor, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m, threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Straight-through estimator for binary variable using the Gumbel-Sigmoid distribution.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Arg(s):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        Two tensors of shape (batch_size, 1) containing the estimated hard and soft probabilities, respectively.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43msample_from_gumbel_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     z \u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     35\u001b[0m     z \u001b[38;5;241m=\u001b[39m (z \u001b[38;5;241m-\u001b[39m y)\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m+\u001b[39m y\n",
      "File \u001b[0;32m~/workspace/HierGAT-2025/pyrutils/torch/distributions.py:16\u001b[0m, in \u001b[0;36msample_from_gumbel_sigmoid\u001b[0;34m(probabilities, temperature)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sample from the Gumbel-Sigmoid distribution.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mArg(s):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    A torch tensor of same shape as probabilities, containing the sampled probabilities for each example.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([probabilities, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m probabilities], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgumbel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGumbel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(probabilities \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-20\u001b[39m) \u001b[38;5;241m+\u001b[39m g\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msoftmax(y \u001b[38;5;241m/\u001b[39m temperature, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, :\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_creation_args = cfg.models.parameters\n",
    "model_creation_args = {**data_info, **model_creation_args.__dict__}\n",
    "dataset_name = cfg.data.name\n",
    "model_creation_args['num_classes'] = (num_classes, None)\n",
    "device = 'cuda' if torch.cuda.is_available() and cfg.resources.use_gpu else 'cpu'\n",
    "model = TGGCN(feat_dim=1024, **model_creation_args).to(device)\n",
    "if misc_dict.get('pretrained', False) and misc_dict.get('pretrained_path') is not None:\n",
    "    state_dict = load_model_weights(misc_dict['pretrained_path'])\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, lr=cfg.models.optimization.learning_rate)\n",
    "criterion, loss_names = select_loss(model_name, model_input_type, dataset_name, cfg=cfg)\n",
    "mtll_model = None\n",
    "if misc_dict.get('multi_task_loss_learner', False):\n",
    "    loss_types = select_loss_types(model_name, dataset_name, cfg=cfg)\n",
    "    mask = select_loss_learning_mask(model_name, dataset_name, cfg=cfg)\n",
    "    mtll_model = MultiTaskLossLearner(loss_types=loss_types, mask=mask).to(device)\n",
    "    optimizer.add_param_group({'params': mtll_model.parameters()})\n",
    "# Some config + model training\n",
    "tensorboard_log_dir = cfg.models.logging.root_log_dir\n",
    "checkpoint_name = cfg.models.logging.checkpoint_name\n",
    "fetch_model_data = select_model_data_fetcher(model_name, model_input_type,\n",
    "                                             dataset_name=dataset_name, **{**misc_dict, **cfg.models.parameters.__dict__})\n",
    "feed_model_data = select_model_data_feeder(model_name, model_input_type, dataset_name=dataset_name, **misc_dict)\n",
    "num_main_losses = decide_num_main_losses(model_name, dataset_name, {**misc_dict, **cfg.models.parameters.__dict__})\n",
    "checkpoint = train(\n",
    "    model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    cfg.models.optimization.epochs, \n",
    "    device, \n",
    "    loss_names,\n",
    "    clip_gradient_at=cfg.models.optimization.clip_gradient_at,\n",
    "    fetch_model_data=fetch_model_data, feed_model_data=feed_model_data,\n",
    "    val_loader=val_loader, \n",
    "    mtll_model=mtll_model, \n",
    "    num_main_losses=num_main_losses,\n",
    "    tensorboard_log_dir=tensorboard_log_dir, \n",
    "    checkpoint_name=checkpoint_name,\n",
    ")\n",
    "# Logging\n",
    "if cfg.models.logging.log_dir is not None:\n",
    "    log_dir = cfg.models.logging.log_dir\n",
    "    checkpoint['scalers'] = scalers\n",
    "    save_checkpoint(log_dir, checkpoint, checkpoint_name=checkpoint_name, include_timestamp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from predict import match_shape, match_att_shape\n",
    "\n",
    "inspect_model = False\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, targets, attentions = [], [], []\n",
    "for i, dataset in enumerate(test_loader):\n",
    "    data, target = fetch_model_data(dataset, device=device)\n",
    "    with torch.no_grad():\n",
    "        output = feed_model_data(model, data)\n",
    "    if inspect_model:\n",
    "        output, attention_scores = output\n",
    "        attention_scores = [att_score[:, 0] for att_score in attention_scores]\n",
    "    if num_main_losses is not None:\n",
    "        output = output[-num_main_losses:]\n",
    "        target = target[-num_main_losses:]\n",
    "    if downsampling > 1:\n",
    "        for i, (out, tgt) in enumerate(zip(output, target)):\n",
    "            if out.ndim != 4:\n",
    "                raise RuntimeError(f'Number of dimensions for output is {out.ndim}')\n",
    "            out = torch.repeat_interleave(out, repeats=downsampling, dim=-2)\n",
    "            out = match_shape(out, tgt)\n",
    "            output[i] = out\n",
    "        if inspect_model:\n",
    "            a_target = target[0]\n",
    "            attention_scores = [torch.repeat_interleave(att_score, repeats=downsampling, dim=-2)\n",
    "                                for att_score in attention_scores]\n",
    "            attention_scores = [match_att_shape(att_score, a_target) for att_score in attention_scores]\n",
    "            attentions.append(attention_scores)\n",
    "    outputs += output\n",
    "    targets += target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.argmax(outputs[0], dim=1)\n",
    "y_pred = y_pred.squeeze(-1).mode(dim=1).values.cpu().numpy()\n",
    "y_true = targets[0].squeeze(-1).mode(dim=1).values.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35537190082644626\n",
      "F1 Score: 0.3163518299881936\n",
      "Precision: 0.3188478188478188\n",
      "Recall: 0.35537190082644626\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = list(range(num_classes))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_torch271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
